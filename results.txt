Linear Regression (100k)
Time to train model: 21.40 min
R^2: 0.65
testing model:
MAE:790449170.247
RMSE: 23111109481.89

Ridge Regression (100k)
Time to train model: 2.37min
R^2: 0.65
testing model:
MAE:0.450
RMSE: 0.60

Tree Regression (100k) (max_depth=150)
Time to train model: 3.96 min
R^2: 0.91
testing model:
MAE:0.398
RMSE: 0.58
depth:  150

Tree Regression (100k) (no max depth)
Time to train model: 4.17 min
R^2: 0.94
testing model:
MAE: 0.397
RMSE: 0.59
depth:  397

Neural Network (100k) 
Iteration 111, loss = 0.04292304
Iteration 112, loss = 0.04271347
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Time to train model: 79.58 min
R^2: 0.89
testing model:
MAE: 0.374
RMSE: 0.55

Tree CV (20K 0.005 min_df)
R-Squared::0.3129453400339397
Best Hyperparameters::
{'criterion': 'mse', 'max_depth': 50, 'max_leaf_nodes': 100, 'min_samples_leaf': 20, 'min_samples_split': 10}
   mean_fit_time  std_fit_time  mean_score_time  ...  mean_test_score std_test_score rank_test_score
0       0.467382      0.006260         0.009866  ...         0.258065       0.014601              94
1       0.472237      0.005962         0.010173  ...         0.258065       0.014601              94
2       0.478636      0.006518         0.010096  ...         0.258065       0.014601              94
3       0.478901      0.006137         0.010284  ...         0.258427       0.014324              91
4       0.485590      0.007259         0.010207  ...         0.258427       0.014324              91

[5 rows x 18 columns]
Evaluating the training model
Checking the training model scores
R^2 for each fold
[0.32190805 0.30499991 0.31265877 0.30909515 0.30729061 0.29349819
 0.30303261 0.31199677 0.32201035 0.3429721 ]
MSE for each fold
[-0.52220668 -0.50123662 -0.49814134 -0.51802412 -0.49832016 -0.49977422
 -0.49282821 -0.49996545 -0.49999215 -0.49067212]
avg R-squared::0.313
MSE::-0.502
Test dataset evaluation
R-squared:0.305
MAE: 0.558
MSE: 0.49